
# "5.3. Введение. Экосистема. Архитектура. Жизненный цикл Docker контейнера" - Захаров Сергей Николаевич


## Задача 1

Сценарий выполения задачи:

- создайте свой репозиторий на https://hub.docker.com;
- выберете любой образ, который содержит веб-сервер Nginx;
- создайте свой fork образа;
- реализуйте функциональность:
запуск веб-сервера в фоне с индекс-страницей, содержащей HTML-код ниже:
```
<html>
<head>
Hey, Netology
</head>
<body>
<h1>I’m DevOps Engineer!</h1>
</body>
</html>
```
Опубликуйте созданный форк в своем репозитории и предоставьте ответ в виде ссылки на https://hub.docker.com/username_repo.

**Ответ:**
- [Ссылка на форк образа nginx ](https://hub.docker.com/layers/182189120/zakharovnpa/nginx/13.12.21/images/sha256-f79caf2a37ea9ab9886f24a855a050c4bc7c8e63ee8adce5ca8b57e5ce741d9e?context=repo)
- [Логи выполнения Задания №1](/05-virt-03-docker/docker-testing/exercise-1.md)


## Задача 2

Посмотрите на сценарий ниже и ответьте на вопрос:
"Подходит ли в этом сценарии использование Docker контейнеров или лучше подойдет виртуальная машина, физическая машина? Может быть возможны разные варианты?"

Детально опишите и обоснуйте свой выбор.

--

Сценарий:

- Высоконагруженное монолитное java веб-приложение;
- Nodejs веб-приложение;
- Мобильное приложение c версиями для Android и iOS;
- Шина данных на базе Apache Kafka;
- Elasticsearch кластер для реализации логирования продуктивного веб-приложения - три ноды elasticsearch, два logstash и две ноды kibana;
- Мониторинг-стек на базе Prometheus и Grafana;
- MongoDB, как основное хранилище данных для java-приложения;
- Gitlab сервер для реализации CI/CD процессов и приватный (закрытый) Docker Registry.

**Ответ:**
- Пояснения на 1:25:45
1. Для высоконагруженного монолитного java веб-приложения подходит комбинация использования Docker контейнеров и виртуальных машин. [Контейнеризация монолитных приложений](https://docs.microsoft.com/ru-ru/dotnet/architecture/microservices/architect-microservice-container-applications/containerize-monolithic-applications)
Для управления этой моделью вы развертываете один контейнер, представляющий собой приложение. Чтобы увеличить емкость, вы используете горизонтальное масштабирование, то есть просто добавляете больше копий с подсистемой балансировки нагрузки спереди. Управлять одним развертыванием в одном контейнере или виртуальной машине гораздо проще.

Недостаток этого подхода становится очевидным, когда приложение разрастается и его необходимо масштабировать. Если можно масштабировать приложение целиком, все получится. Но в большинстве случаев необходимо масштабировать всего несколько частей приложения, пока другие компоненты работают нормально.

[Развертывание монолитного приложения в контейнере](https://docs.microsoft.com/ru-ru/dotnet/architecture/microservices/architect-microservice-container-applications/containerize-monolithic-applications#deploying-a-monolithic-application-as-a-container)

Использование контейнеров для управления развертываниями монолитных приложений имеет свои преимущества. Масштабировать экземпляры контейнера гораздо быстрее и проще, чем развертывать дополнительные виртуальные машины. Даже при использовании масштабируемых наборов виртуальных машин им необходимо время на запуск. При развертывании в виде традиционных экземпляров приложений вместо контейнеров настройками приложения приходится управлять в рамках виртуальной машины, и это не лучшее решение.

Развертывание обновлений в виде образов Docker выполняется гораздо быстрее и эффективнее с точки зрения использования сети. Образы Docker обычно запускаются за считанные секунды, что позволяет ускорить выпуск. Остановить образ Docker можно с помощью команды docker stop, и обычно это происходит моментально.

Поскольку контейнеры неизменны по своей природе, вам не придется беспокоиться о поврежденных виртуальных машинах. Напротив, скрипты обновления для виртуальной машины могут не учесть определенную конфигурацию или забыть файл на диске.

Docker имеет много плюсов для монолитных приложений, но это еще не полный список преимуществ. Дополнительные возможности при управлении контейнерами открываются благодаря развертыванию с помощью оркестраторов контейнеров, которые управляют различными экземплярами и жизненным циклом каждого экземпляра контейнера. Когда вы разбиваете монолитное приложение на подсистемы, которые затем можно масштабировать, разрабатывать и развертывать по отдельности, вы переходите на уровень микрослужб.

2. Для Nodejs веб-приложения подходит использование Docker контейнеров

Node.js — это серверная среда выполнения JavaScript, выполняющая код JavaScript.
Служба приложений Linux развертывает контейнер Docker для Linux для запуска приложения Node.js

[Публикация приложения Node.js в Azure (служба приложений Linux)](https://docs.microsoft.com/ru-ru/visualstudio/javascript/publish-nodejs-app-azure?view=vs-2022#create-a-linux-app-service-in-azure)

3. Для мобильного приложения c версиями для Android и iOS контейнер не подходит, т.к. здесь необходимо физическое устройство в установленной конкретной ОС.

Мобильное приложение (англ. «Mobile app») — программное обеспечение, предназначенное для работы на смартфонах, планшетах и других мобильных устройствах[1], разработанное для конкретной платформы (iOS, Android, Windows Phone и т. д.). Многие мобильные приложения предустановлены на самом устройстве или могут быть загружены на него из онлайновых магазинов приложений. [Мобильное приложение](https://ru.wikipedia.org/wiki/%D0%9C%D0%BE%D0%B1%D0%B8%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5)


4. Шина данных на базе Apache Kafka - необходимы кластеры на ВМ?
Apache Kafka - это распределенная потоковая платформа. В данном случае предоставляется шина с колоссальной пропускной способностью, на которой можно в реальном времени обрабатывать абсолютно все проходящие через нее данные.
- [Apache Kafka](https://ru.wikipedia.org/wiki/Apache_Kafka)
- [Шины данных](https://mcs.mail.ru/docs/ru/base/bigdata/bigdata-integrate/esb)
- [Нервная система бэкенда: зачем нужен Apache Kafka](https://mcs.mail.ru/blog/apache-kafka-chto-eto-i-kak-rabotaet)
- [Масштабирование](https://mcs.mail.ru/docs/ru/base/bigdata/bigdata-integrate/esb#:~:text=%D0%9A%D0%B0%D0%BA%20%D0%B8%20%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D0%BD%D1%81%D1%82%D0%B2%D0%BE%20%D1%81%D0%BE%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D1%8F%D1%8E%D1%89%D0%B8%D1%85%20%D0%B2%20%D1%8D%D0%BA%D0%BE%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B5%20Hadoop%2C%20%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%20Kafka%20%D1%81%D0%BF%D0%BE%D1%81%D0%BE%D0%B1%D0%B5%D0%BD%20%D0%BC%D0%B0%D1%81%D1%88%D1%82%D0%B0%D0%B1%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D1%82%D1%8C%D1%81%D1%8F%20%D0%BD%D0%B0%20%D0%B1%D0%B5%D1%81%D0%BA%D0%BE%D0%BD%D0%B5%D1%87%D0%BD%D0%BE%D0%B5%20%D1%87%D0%B8%D1%81%D0%BB%D0%BE%20%D1%83%D0%B7%D0%BB%D0%BE%D0%B2.)
Kafka был разработан в компании LinkedIn в 2011 году и с тех пор значительно усовершенствовался. Сегодня Kafka – это целая платформа, обеспечивающая избыточность, достаточную для хранения абсурдно огромных объемов данных. Здесь предоставляется шина сообщений с колоссальной пропускной способностью, на которой можно в реальном времени обрабатывать абсолютно все проходящие через нее данные.
- [Apache Kafka: обзор](https://habr.com/ru/company/piter/blog/352978/)
- [СОБЕННОСТИ КОРПОРАТИВНОЙ ИНТЕГРАЦИИ НА ESB И APACHE KAFKA](https://www.bigdataschool.ru/blog/kafka-esb-avito-case.html)

5. Elasticsearch кластер для реализации логирования продуктивного веб-приложения - три ноды elasticsearch, два logstash и две ноды kibana
Необходимо на кластере из трех серверов

- [Развертывание отказоустойчивого кластера Elasticsearch в Linux](https://netpoint-dc.com/blog/elasticsearch-cluster-linux/)
- [Что же такое Logstash? Зачем он нужен? Что он умеет?](https://habr.com/ru/post/165059/#:~:text=%D0%A7%D1%82%D0%BE%20%D0%B6%D0%B5%20%D1%82%D0%B0%D0%BA%D0%BE%D0%B5%20Logstash%3F%20%D0%97%D0%B0%D1%87%D0%B5%D0%BC%20%D0%BE%D0%BD%20%D0%BD%D1%83%D0%B6%D0%B5%D0%BD%3F%20%D0%A7%D1%82%D0%BE%20%D0%BE%D0%BD%20%D1%83%D0%BC%D0%B5%D0%B5%D1%82%3F)
- []()
- []()

Elasticsearch — это масштабируемый полнотекстовый поисковый и аналитический поисковый движок с открытым исходным кодом, позволяющий хранить большие объемы данных, проводить среди них быстрый поиск и аналитику. Он является чрезвычайно мощным инструментом для поиска и анализа данных, благодаря его способности к масштабированию. Описание всех преимуществ этого движка доступно на [официальном сайте](https://www.elastic.co/products/elasticsearch).



- Мониторинг-стек на базе Prometheus и Grafana;
- MongoDB, как основное хранилище данных для java-приложения;
- Gitlab сервер для реализации CI/CD процессов и приватный (закрытый) Docker Registry.

## Задача 3

- Запустите первый контейнер из образа ***centos*** c любым тэгом в фоновом режиме, подключив папку ```/data``` из текущей рабочей директории на хостовой машине в ```/data``` контейнера;
- Запустите второй контейнер из образа ***debian*** в фоновом режиме, подключив папку ```/data``` из текущей рабочей директории на хостовой машине в ```/data``` контейнера;
- Подключитесь к первому контейнеру с помощью ```docker exec``` и создайте текстовый файл любого содержания в ```/data```;
- Добавьте еще один файл в папку ```/data``` на хостовой машине;
- Подключитесь во второй контейнер и отобразите листинг и содержание файлов в ```/data``` контейнера.

**Ответ:**

### 1. Запускаем первый контейнер из образа ***centos*** c любым тэгом в фоновом режиме, подключив папку ```/data``` из текущей рабочей директории на хостовой машине в ```/data``` контейнера;

```bash
root@server1:~# docker image ls
REPOSITORY            TAG        IMAGE ID       CREATED          SIZE
zakharovnpa/debian    009        888b869de873   30 minutes ago   124MB
zakharovnpa/centos7   001        62ad6751e301   13 hours ago     261MB
```
```bash
root@server1:~/build/debian# docker run -v /root/data:/tmp/data --name=Ford_Fusion -d 62ad6751e301
```
#### Запущенный контейнер
```bash
root@server1:~# docker ps
CONTAINER ID   IMAGE          COMMAND            CREATED         STATUS         PORTS     NAMES
28f057cad73e   62ad6751e301   "/usr/sbin/init"   5 minutes ago   Up 5 minutes   80/tcp    Ford_Fusion
```
### 2. Запускаем второй контейнер из образа ***debian*** в фоновом режиме, подключив папку ```/data``` из текущей рабочей директории на хостовой машине в ```/data``` контейнера;

```bash
root@server1:~# docker run -v /root/data:/tmp/data --name=Ford_Fiesta -d 888b869de873
6f12266c6324cb77bba5babbcd10162054146cc81811fd2e74a9e786e6e78f9f
```
#### Запущенные контейнеры
```bash
root@server1:~# docker ps
CONTAINER ID   IMAGE          COMMAND            CREATED          STATUS          PORTS     NAMES
6f12266c6324   888b869de873   "/usr/sbin/init"   8 seconds ago    Up 6 seconds    80/tcp    Ford_Fiesta
28f057cad73e   62ad6751e301   "/usr/sbin/init"   26 minutes ago   Up 26 minutes   80/tcp    Ford_Fusion
```

#### 3. Подключаемся к первому контейнеру с помощью ```docker exec``` и создаем текстовый файл любого содержания в ```/data```;
```bash
root@server1:~# docker exec -it Ford_Fusion bash
[root@28f057cad73e /]# 
[root@28f057cad73e /]# cd tmp/data
[root@28f057cad73e data]# ls -l
total 0
```
###### Создаем пустой файл, т.к. в контейнере не оказалось никакого редактора
```bash

[root@28f057cad73e data]# touch File-1.txt
[root@28f057cad73e data]# 
[root@28f057cad73e data]# ls -l
total 1
-rw-r--r-- 1 root root   0 Dec 14 05:06 File-1.txt
[root@28f057cad73e data]# 
```

##### 4. На хостовой машине редактируем первый файл и создаем второй файл в папку ```/data``` ;
```bash
root@server1:~# cd data
root@server1:~/data# 
root@server1:~/data# vim File-1.txt
root@server1:~/data# 
root@server1:~/data# cat File-1.txt
The is a file "File-1.txt"
root@server1:~/data# 
root@server1:~/data# vim File-2.txt
root@server1:~/data# 
root@server1:~/data# cat File-2.txt
The is a file "File-2.txt"
root@server1:~/data# ls -l
total 2
-rw-r--r-- 1 root root   0 Dec 14 05:06 File-1.txt
-rw-r--r-- 1 root root 370 Dec 14 05:14 File-2.txt
root@server1:~/data# 
```

##### 5. Подключаемся во второй контейнер и отображаем листинг и содержание файлов в ```/data``` контейнера.
```bash
root@server1:~# docker exec -it Ford_Fiesta bash
[root@6f12266c6324 /]# 
[root@6f12266c6324 /]# cd /tmp/data
[root@6f12266c6324 data]# 
[root@6f12266c6324 data]# ls -l
total 2
-rw-r--r-- 1 root root   0 Dec 14 05:06 File-1.txt
-rw-r--r-- 1 root root 370 Dec 14 05:14 File-2.txt
```
```bash
[root@6f12266c6324 data]# cat File-1.txt
The is a file "File-1.txt"
```
```bash
[root@6f12266c6324 data]# cat File-2.txt
The is a file "File-2.txt"

```

## Задача 4 (*)

Воспроизвести практическую часть лекции самостоятельно.

Соберите Docker образ с Ansible, загрузите на Docker Hub и пришлите ссылку вместе с остальными ответами к задачам.

**Ответ:**
- Пояснения на 1:27:25

- [Ссылка на собранный образ](https://hub.docker.com/layers/181355580/zakharovnpa/ansible/8.12.21/images/sha256-f48001cc499c344a8c95119bb736c38c56adf770cdac072b6e615e12d4b674cd?context=repo)

---

