
# "5.3. Введение. Экосистема. Архитектура. Жизненный цикл Docker контейнера" - Захаров Сергей Николаевич


## Задача 1

Сценарий выполения задачи:

- создайте свой репозиторий на https://hub.docker.com;
- выберете любой образ, который содержит веб-сервер Nginx;
- создайте свой fork образа;
- реализуйте функциональность:
запуск веб-сервера в фоне с индекс-страницей, содержащей HTML-код ниже:
```
<html>
<head>
Hey, Netology
</head>
<body>
<h1>I’m DevOps Engineer!</h1>
</body>
</html>
```
Опубликуйте созданный форк в своем репозитории и предоставьте ответ в виде ссылки на https://hub.docker.com/username_repo.

**Ответ:**
- [Ссылка на форк образа nginx ](https://hub.docker.com/layers/182189120/zakharovnpa/nginx/13.12.21/images/sha256-f79caf2a37ea9ab9886f24a855a050c4bc7c8e63ee8adce5ca8b57e5ce741d9e?context=repo)

### Для решения задачи необходимо было создать новый образ с заявленными изменениями из образа nginx
#### Создаем Dockerfile и файл index.html
```bash
# Манифест Docker образа.

FROM nginx

# Заменяем дефолтную страницу nginx соответствующей веб-приложению
RUN rm -rf /usr/share/nginx/html/*

# Копируем новый файл index.html в каталог на будующем образе
COPY ./html/index.html /usr/share/nginx/html

```
#### Файл index.html
```bash
<html>
<head>
Hey, Netology
</head>
<body>
<h1>I’m DevOps Engineer!</h1>
</body>
</html>

```
#### Запускаем создание образа
```bash
root@server1:~/build/nginx# docker build -t zakharovnpa/nginx:13.12.21 .
Sending build context to Docker daemon  4.608kB
Step 1/3 : FROM nginx
 ---> f652ca386ed1
Step 2/3 : RUN rm -rf /usr/share/nginx/html/*
 ---> Running in 58d18923e45b
Removing intermediate container 58d18923e45b
 ---> 993637835b2b
Step 3/3 : COPY ./html/index.html /usr/share/nginx/html
 ---> 4b8b755d634a
Successfully built 4b8b755d634a
Successfully tagged zakharovnpa/nginx:13.12.21
```
#### Образ создан
```bash
root@server1:~/build/nginx# docker image ls
REPOSITORY            TAG        IMAGE ID       CREATED         SIZE
zakharovnpa/nginx     13.12.21   4b8b755d634a   9 seconds ago   141MB

```
#### Запускаем контейнер
```bash
root@server1:~/build/nginx# docker run --name=Alfa-nginx -p 80:80 -d zakharovnpa/nginx:13.12.21
0a2533d58415906a2c34fa8bbf0833112434192a286ef2e46b87fde3c085db90
root@server1:~/build/nginx# 
root@server1:~/build/nginx# 
root@server1:~/build/nginx# docker ps
CONTAINER ID   IMAGE                        COMMAND                  CREATED          STATUS          PORTS                               NAMES
0a2533d58415   zakharovnpa/nginx:13.12.21   "/docker-entrypoint.…"   14 seconds ago   Up 12 seconds   0.0.0.0:80->80/tcp, :::80->80/tcp   Alfa-nginx

```
#### Проеряем ответ сервера
```bash
root@server1:~/build/nginx# curl -X GET 'http://127.0.0.1:80'
<html>
<head>
Hey, Netology
</head>
<body>
<h1>I’m DevOps Engineer!</h1>
</body>
</html>

```
#### Ответ сервера в браузере
![i-am-devops-engeneer](/)

## Задача 2

Посмотрите на сценарий ниже и ответьте на вопрос:
"Подходит ли в этом сценарии использование Docker контейнеров или лучше подойдет виртуальная машина, физическая машина? Может быть возможны разные варианты?"

Детально опишите и обоснуйте свой выбор.

--

Сценарий:

- Высоконагруженное монолитное java веб-приложение;
- Nodejs веб-приложение;
- Мобильное приложение c версиями для Android и iOS;
- Шина данных на базе Apache Kafka;
- Elasticsearch кластер для реализации логирования продуктивного веб-приложения - три ноды elasticsearch, два logstash и две ноды kibana;
- Мониторинг-стек на базе Prometheus и Grafana;
- MongoDB, как основное хранилище данных для java-приложения;
- Gitlab сервер для реализации CI/CD процессов и приватный (закрытый) Docker Registry.

**Ответ:**

1. Для высоконагруженного монолитного java веб-приложения подходит комбинация использования Docker контейнеров и виртуальных машин. [Контейнеризация монолитных приложений](https://docs.microsoft.com/ru-ru/dotnet/architecture/microservices/architect-microservice-container-applications/containerize-monolithic-applications)
Для управления этой моделью вы развертываете один контейнер, представляющий собой приложение. Чтобы увеличить емкость, вы используете горизонтальное масштабирование, то есть просто добавляете больше копий с подсистемой балансировки нагрузки спереди. Управлять одним развертыванием в одном контейнере или виртуальной машине гораздо проще.

Недостаток этого подхода становится очевидным, когда приложение разрастается и его необходимо масштабировать. Если можно масштабировать приложение целиком, все получится. Но в большинстве случаев необходимо масштабировать всего несколько частей приложения, пока другие компоненты работают нормально.

[Развертывание монолитного приложения в контейнере](https://docs.microsoft.com/ru-ru/dotnet/architecture/microservices/architect-microservice-container-applications/containerize-monolithic-applications#deploying-a-monolithic-application-as-a-container)

Использование контейнеров для управления развертываниями монолитных приложений имеет свои преимущества. Масштабировать экземпляры контейнера гораздо быстрее и проще, чем развертывать дополнительные виртуальные машины. Даже при использовании масштабируемых наборов виртуальных машин им необходимо время на запуск. При развертывании в виде традиционных экземпляров приложений вместо контейнеров настройками приложения приходится управлять в рамках виртуальной машины, и это не лучшее решение.

Развертывание обновлений в виде образов Docker выполняется гораздо быстрее и эффективнее с точки зрения использования сети. Образы Docker обычно запускаются за считанные секунды, что позволяет ускорить выпуск. Остановить образ Docker можно с помощью команды docker stop, и обычно это происходит моментально.

Поскольку контейнеры неизменны по своей природе, вам не придется беспокоиться о поврежденных виртуальных машинах. Напротив, скрипты обновления для виртуальной машины могут не учесть определенную конфигурацию или забыть файл на диске.

Docker имеет много плюсов для монолитных приложений, но это еще не полный список преимуществ. Дополнительные возможности при управлении контейнерами открываются благодаря развертыванию с помощью оркестраторов контейнеров, которые управляют различными экземплярами и жизненным циклом каждого экземпляра контейнера. Когда вы разбиваете монолитное приложение на подсистемы, которые затем можно масштабировать, разрабатывать и развертывать по отдельности, вы переходите на уровень микрослужб.

2. Для Nodejs веб-приложения подходит использование Docker контейнеров

Node.js — это серверная среда выполнения JavaScript, выполняющая код JavaScript.
Служба приложений Linux развертывает контейнер Docker для Linux для запуска приложения Node.js

[Публикация приложения Node.js в Azure (служба приложений Linux)](https://docs.microsoft.com/ru-ru/visualstudio/javascript/publish-nodejs-app-azure?view=vs-2022#create-a-linux-app-service-in-azure)

3. Для мобильного приложения c версиями для Android и iOS контейнер не подходит, т.к. здесь необходимо физическое устройство в установленной конкретной ОС.

Мобильное приложение (англ. «Mobile app») — программное обеспечение, предназначенное для работы на смартфонах, планшетах и других мобильных устройствах[1], разработанное для конкретной платформы (iOS, Android, Windows Phone и т. д.). Многие мобильные приложения предустановлены на самом устройстве или могут быть загружены на него из онлайновых магазинов приложений. [Мобильное приложение](https://ru.wikipedia.org/wiki/%D0%9C%D0%BE%D0%B1%D0%B8%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5)


4. Шина данных на базе Apache Kafka - необходимы кластеры на ВМ?
Apache Kafka - это распределенная потоковая платформа. В данном случае предоставляется шина с колоссальной пропускной способностью, на которой можно в реальном времени обрабатывать абсолютно все проходящие через нее данные.
- [Apache Kafka](https://ru.wikipedia.org/wiki/Apache_Kafka)
- [Шины данных](https://mcs.mail.ru/docs/ru/base/bigdata/bigdata-integrate/esb)
- [Нервная система бэкенда: зачем нужен Apache Kafka](https://mcs.mail.ru/blog/apache-kafka-chto-eto-i-kak-rabotaet)
- [Масштабирование](https://mcs.mail.ru/docs/ru/base/bigdata/bigdata-integrate/esb#:~:text=%D0%9A%D0%B0%D0%BA%20%D0%B8%20%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D0%BD%D1%81%D1%82%D0%B2%D0%BE%20%D1%81%D0%BE%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D1%8F%D1%8E%D1%89%D0%B8%D1%85%20%D0%B2%20%D1%8D%D0%BA%D0%BE%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B5%20Hadoop%2C%20%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%20Kafka%20%D1%81%D0%BF%D0%BE%D1%81%D0%BE%D0%B1%D0%B5%D0%BD%20%D0%BC%D0%B0%D1%81%D1%88%D1%82%D0%B0%D0%B1%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D1%82%D1%8C%D1%81%D1%8F%20%D0%BD%D0%B0%20%D0%B1%D0%B5%D1%81%D0%BA%D0%BE%D0%BD%D0%B5%D1%87%D0%BD%D0%BE%D0%B5%20%D1%87%D0%B8%D1%81%D0%BB%D0%BE%20%D1%83%D0%B7%D0%BB%D0%BE%D0%B2.)
Kafka был разработан в компании LinkedIn в 2011 году и с тех пор значительно усовершенствовался. Сегодня Kafka – это целая платформа, обеспечивающая избыточность, достаточную для хранения абсурдно огромных объемов данных. Здесь предоставляется шина сообщений с колоссальной пропускной способностью, на которой можно в реальном времени обрабатывать абсолютно все проходящие через нее данные.
- [Apache Kafka: обзор](https://habr.com/ru/company/piter/blog/352978/)
- [СОБЕННОСТИ КОРПОРАТИВНОЙ ИНТЕГРАЦИИ НА ESB И APACHE KAFKA](https://www.bigdataschool.ru/blog/kafka-esb-avito-case.html)

5. Elasticsearch кластер для реализации логирования продуктивного веб-приложения - три ноды elasticsearch, два logstash и две ноды kibana
Необходимо на кластере из трех серверов

- [Развертывание отказоустойчивого кластера Elasticsearch в Linux](https://netpoint-dc.com/blog/elasticsearch-cluster-linux/)
- [Что же такое Logstash? Зачем он нужен? Что он умеет?](https://habr.com/ru/post/165059/#:~:text=%D0%A7%D1%82%D0%BE%20%D0%B6%D0%B5%20%D1%82%D0%B0%D0%BA%D0%BE%D0%B5%20Logstash%3F%20%D0%97%D0%B0%D1%87%D0%B5%D0%BC%20%D0%BE%D0%BD%20%D0%BD%D1%83%D0%B6%D0%B5%D0%BD%3F%20%D0%A7%D1%82%D0%BE%20%D0%BE%D0%BD%20%D1%83%D0%BC%D0%B5%D0%B5%D1%82%3F)
- []()
- []()

Elasticsearch — это масштабируемый полнотекстовый поисковый и аналитический поисковый движок с открытым исходным кодом, позволяющий хранить большие объемы данных, проводить среди них быстрый поиск и аналитику. Он является чрезвычайно мощным инструментом для поиска и анализа данных, благодаря его способности к масштабированию. Описание всех преимуществ этого движка доступно на [официальном сайте](https://www.elastic.co/products/elasticsearch).



- Мониторинг-стек на базе Prometheus и Grafana;
- MongoDB, как основное хранилище данных для java-приложения;
- Gitlab сервер для реализации CI/CD процессов и приватный (закрытый) Docker Registry.

## Задача 3

- Запустите первый контейнер из образа ***centos*** c любым тэгом в фоновом режиме, подключив папку ```/data``` из текущей рабочей директории на хостовой машине в ```/data``` контейнера;
- Запустите второй контейнер из образа ***debian*** в фоновом режиме, подключив папку ```/data``` из текущей рабочей директории на хостовой машине в ```/data``` контейнера;
- Подключитесь к первому контейнеру с помощью ```docker exec``` и создайте текстовый файл любого содержания в ```/data```;
- Добавьте еще один файл в папку ```/data``` на хостовой машине;
- Подключитесь во второй контейнер и отобразите листинг и содержание файлов в ```/data``` контейнера.

**Ответ:**
Как работать с Volume

## Задача 4 (*)

Воспроизвести практическую часть лекции самостоятельно.

Соберите Docker образ с Ansible, загрузите на Docker Hub и пришлите ссылку вместе с остальными ответами к задачам.

**Ответ:**

- [Ссылка на собранный образ](https://hub.docker.com/layers/181355580/zakharovnpa/ansible/8.12.21/images/sha256-f48001cc499c344a8c95119bb736c38c56adf770cdac072b6e615e12d4b674cd?context=repo)

---

